# Configuration file
# key = value
# configure your datasource
%prod.quarkus.datasource.url=jdbc:postgresql://postgresql-database:5432/person
%prod.quarkus.datasource.driver=org.postgresql.Driver
%dev.quarkus.datasource.url=jdbc:h2:mem:person:default
%dev.quarkus.datasource.driver=org.h2.Driver
%test.quarkus.datasource.url=jdbc:h2:mem:person:default
%test.quarkus.datasource.driver=org.h2.Driver

quarkus.datasource.username=sa
quarkus.datasource.password=sa

# drop and create the database at startup (use `update` to only update the schema)
quarkus.hibernate-orm.database.generation=drop-and-create

quarkus.http.test-port=8083

%prod.quarkus.kubernetes-client.trust-certs=true
%prod.quarkus.container-image.build=true
%prod.quarkus.kubernetes.deploy=true
%prod.quarkus.kubernetes.deployment-target=openshift
%prod.quarkus.openshift.expose=true
%prod.quarkus.openshift.labels.app.openshift.io/runtime=quarkus

quarkus.swagger-ui.always-include=true
quarkus.s2i.base-jvm-image=registry.access.redhat.com/openjdk/openjdk-11-rhel7


# DEV Configure the Kafka sink (we write to it)
%dev.mp.messaging.outgoing.generated-name.bootstrap.servers=facility-cluster-kafka-bootstrap-user1-project.apps.cluster-dia-f806.dia-f806.sandbox1469.opentlc.com:443
%dev.mp.messaging.outgoing.generated-name.connector=smallrye-kafka
%dev.mp.messaging.outgoing.generated-name.topic=names
%dev.mp.messaging.outgoing.generated-name.value.serializer=org.apache.kafka.common.serialization.StringSerializer

# DEV Configure the Kafka source (we read from it)
%dev.mp.messaging.incoming.names.bootstrap.servers=facility-cluster-kafka-bootstrap-user1-project.apps.cluster-dia-f806.dia-f806.sandbox1469.opentlc.com:443
%dev.mp.messaging.incoming.names.connector=smallrye-kafka
%dev.mp.messaging.incoming.names.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer

# Configure the Kafka sink (we write to it)
# %prod.mp.messaging.outgoing.generated-name.bootstrap.servers=names-cluster-kafka-bootstrap:9092
# %prod.mp.messaging.outgoing.generated-name.connector=smallrye-kafka
# %prod.mp.messaging.outgoing.generated-name.topic=names
# %prod.mp.messaging.outgoing.generated-name.value.serializer=org.apache.kafka.common.serialization.StringSerializer

# Configure the Kafka source (we read from it)
# %prod.mp.messaging.incoming.names.bootstrap.servers=names-cluster-kafka-bootstrap:9092
# %prod.mp.messaging.incoming.names.connector=smallrye-kafka
# %prod.mp.messaging.incoming.names.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer


# Configure the Kafka sink (we write to it)
%prod.mp.messaging.outgoing.generated-name.bootstrap.servers=facility-cluster-kafka-bootstrap:9092
%prod.mp.messaging.outgoing.generated-name.connector=smallrye-kafka
%prod.mp.messaging.outgoing.generated-name.topic=names
%prod.mp.messaging.outgoing.generated-name.value.serializer=org.apache.kafka.common.serialization.StringSerializer

# Configure the Kafka source (we read from it)
%prod.mp.messaging.incoming.names.bootstrap.servers=facility-cluster-kafka-bootstrap:9092
%prod.mp.messaging.incoming.names.connector=smallrye-kafka
%prod.mp.messaging.incoming.names.value.deserializer=org.apache.kafka.common.serialization.StringDeserializer